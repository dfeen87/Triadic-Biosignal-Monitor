{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Computation: ΔS, ΔI, ΔC\n",
    "\n",
    "This notebook demonstrates computation of the three deviation terms in the unified instability gate:\n",
    "\n",
    "$$\\Delta\\Phi(t) = \\alpha|\\Delta S(t)| + \\beta|\\Delta I(t)| + \\gamma|\\Delta C(t)|$$\n",
    "\n",
    "where:\n",
    "- **ΔS**: Spectral/morphological deviation\n",
    "- **ΔI**: Information/entropy deviation\n",
    "- **ΔC**: Cross-modal coupling deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal, stats\n",
    "from scipy.signal import hilbert, welch\n",
    "from scipy.stats import entropy\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Spectral Deviation (ΔS)\n",
    "\n",
    "Spectral deviation captures changes in frequency content relative to baseline.\n",
    "\n",
    "For HRV, this includes:\n",
    "- LF/HF ratio changes\n",
    "- Power redistribution across bands\n",
    "- Morphological drift (QRS/QT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_features(signal_data, fs, nperseg=256):\n",
    "    \"\"\"\n",
    "    Compute power spectral density and band powers.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    signal_data : array_like\n",
    "        Input time series\n",
    "    fs : float\n",
    "        Sampling frequency\n",
    "    nperseg : int\n",
    "        Length of each segment for Welch's method\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    features : dict\n",
    "        Spectral features including band powers\n",
    "    \"\"\"\n",
    "    # Compute PSD using Welch's method\n",
    "    freqs, psd = welch(signal_data, fs=fs, nperseg=nperseg)\n",
    "    \n",
    "    # Define frequency bands\n",
    "    delta = (0.5, 4)    # Delta band\n",
    "    theta = (4, 8)      # Theta band\n",
    "    alpha = (8, 13)     # Alpha band\n",
    "    beta = (13, 30)     # Beta band\n",
    "    gamma = (30, 50)    # Gamma band\n",
    "    \n",
    "    # For HRV\n",
    "    vlf = (0.003, 0.04) # Very low frequency\n",
    "    lf = (0.04, 0.15)   # Low frequency\n",
    "    hf = (0.15, 0.4)    # High frequency\n",
    "    \n",
    "    def band_power(freqs, psd, band):\n",
    "        \"\"\"Calculate power in frequency band.\"\"\"\n",
    "        idx = np.logical_and(freqs >= band[0], freqs <= band[1])\n",
    "        return np.trapz(psd[idx], freqs[idx])\n",
    "    \n",
    "    features = {\n",
    "        'total_power': np.trapz(psd, freqs),\n",
    "        'delta_power': band_power(freqs, psd, delta),\n",
    "        'theta_power': band_power(freqs, psd, theta),\n",
    "        'alpha_power': band_power(freqs, psd, alpha),\n",
    "        'beta_power': band_power(freqs, psd, beta),\n",
    "        'gamma_power': band_power(freqs, psd, gamma),\n",
    "        'vlf_power': band_power(freqs, psd, vlf),\n",
    "        'lf_power': band_power(freqs, psd, lf),\n",
    "        'hf_power': band_power(freqs, psd, hf),\n",
    "        'freqs': freqs,\n",
    "        'psd': psd\n",
    "    }\n",
    "    \n",
    "    # LF/HF ratio (autonomic balance marker)\n",
    "    if features['hf_power'] > 0:\n",
    "        features['lf_hf_ratio'] = features['lf_power'] / features['hf_power']\n",
    "    else:\n",
    "        features['lf_hf_ratio'] = np.nan\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def compute_delta_S(current_features, baseline_features):\n",
    "    \"\"\"\n",
    "    Compute spectral deviation from baseline.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    current_features : dict\n",
    "        Spectral features for current window\n",
    "    baseline_features : dict\n",
    "        Spectral features for baseline window\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    delta_s : float\n",
    "        Normalized spectral deviation\n",
    "    \"\"\"\n",
    "    # Compare total power\n",
    "    power_dev = abs(\n",
    "        current_features['total_power'] - baseline_features['total_power']\n",
    "    ) / (baseline_features['total_power'] + 1e-10)\n",
    "    \n",
    "    # Compare LF/HF ratio (for HRV)\n",
    "    if not np.isnan(current_features['lf_hf_ratio']) and \\\n",
    "       not np.isnan(baseline_features['lf_hf_ratio']):\n",
    "        lf_hf_dev = abs(\n",
    "            current_features['lf_hf_ratio'] - baseline_features['lf_hf_ratio']\n",
    "        ) / (baseline_features['lf_hf_ratio'] + 1e-10)\n",
    "    else:\n",
    "        lf_hf_dev = 0\n",
    "    \n",
    "    # Combined spectral deviation\n",
    "    delta_s = 0.5 * power_dev + 0.5 * lf_hf_dev\n",
    "    \n",
    "    return delta_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Information Deviation (ΔI)\n",
    "\n",
    "Information deviation measures changes in entropy and complexity.\n",
    "\n",
    "Methods include:\n",
    "- Sample entropy\n",
    "- Approximate entropy\n",
    "- Permutation entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_entropy(signal_data, m=2, r=0.2):\n",
    "    \"\"\"\n",
    "    Compute sample entropy (complexity measure).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    signal_data : array_like\n",
    "        Input time series\n",
    "    m : int\n",
    "        Embedding dimension\n",
    "    r : float\n",
    "        Tolerance (as fraction of std)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    sampen : float\n",
    "        Sample entropy value\n",
    "    \"\"\"\n",
    "    N = len(signal_data)\n",
    "    r = r * np.std(signal_data)\n",
    "    \n",
    "    def _maxdist(x_i, x_j):\n",
    "        return max([abs(ua - va) for ua, va in zip(x_i, x_j)])\n",
    "    \n",
    "    def _phi(m):\n",
    "        x = [[signal_data[j] for j in range(i, i + m - 1 + 1)] \n",
    "             for i in range(N - m + 1)]\n",
    "        C = [len([1 for j in range(len(x)) \n",
    "                  if i != j and _maxdist(x[i], x[j]) <= r]) \n",
    "             for i in range(len(x))]\n",
    "        return sum(C)\n",
    "    \n",
    "    phi_m = _phi(m)\n",
    "    phi_m_plus = _phi(m + 1)\n",
    "    \n",
    "    if phi_m == 0 or phi_m_plus == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    return -np.log(phi_m_plus / phi_m)\n",
    "\n",
    "\n",
    "def permutation_entropy(signal_data, order=3, delay=1):\n",
    "    \"\"\"\n",
    "    Compute permutation entropy.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    signal_data : array_like\n",
    "        Input time series\n",
    "    order : int\n",
    "        Permutation order\n",
    "    delay : int\n",
    "        Time delay\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pe : float\n",
    "        Permutation entropy\n",
    "    \"\"\"\n",
    "    n = len(signal_data)\n",
    "    permutations = {}\n",
    "    \n",
    "    for i in range(n - delay * (order - 1)):\n",
    "        # Extract pattern\n",
    "        pattern = signal_data[i:i + delay * order:delay]\n",
    "        # Get permutation (rank order)\n",
    "        perm = tuple(np.argsort(pattern))\n",
    "        \n",
    "        if perm in permutations:\n",
    "            permutations[perm] += 1\n",
    "        else:\n",
    "            permutations[perm] = 1\n",
    "    \n",
    "    # Calculate entropy\n",
    "    frequencies = np.array(list(permutations.values()))\n",
    "    probabilities = frequencies / frequencies.sum()\n",
    "    \n",
    "    pe = entropy(probabilities)\n",
    "    # Normalize\n",
    "    pe = pe / np.log(np.math.factorial(order))\n",
    "    \n",
    "    return pe\n",
    "\n",
    "\n",
    "def compute_information_features(signal_data):\n",
    "    \"\"\"\n",
    "    Compute information-theoretic features.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    features : dict\n",
    "        Information features\n",
    "    \"\"\"\n",
    "    features = {\n",
    "        'sample_entropy': sample_entropy(signal_data),\n",
    "        'permutation_entropy': permutation_entropy(signal_data),\n",
    "    }\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def compute_delta_I(current_features, baseline_features):\n",
    "    \"\"\"\n",
    "    Compute information deviation from baseline.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    current_features : dict\n",
    "        Information features for current window\n",
    "    baseline_features : dict\n",
    "        Information features for baseline window\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    delta_i : float\n",
    "        Normalized information deviation\n",
    "    \"\"\"\n",
    "    # Sample entropy deviation\n",
    "    if not np.isnan(current_features['sample_entropy']) and \\\n",
    "       not np.isnan(baseline_features['sample_entropy']):\n",
    "        sampen_dev = abs(\n",
    "            current_features['sample_entropy'] - baseline_features['sample_entropy']\n",
    "        ) / (baseline_features['sample_entropy'] + 1e-10)\n",
    "    else:\n",
    "        sampen_dev = 0\n",
    "    \n",
    "    # Permutation entropy deviation\n",
    "    permen_dev = abs(\n",
    "        current_features['permutation_entropy'] - baseline_features['permutation_entropy']\n",
    "    )\n",
    "    \n",
    "    # Combined information deviation\n",
    "    delta_i = 0.5 * sampen_dev + 0.5 * permen_dev\n",
    "    \n",
    "    return delta_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Coupling Deviation (ΔC)\n",
    "\n",
    "Coupling deviation measures changes in cross-modal synchronization between EEG and ECG/HRV.\n",
    "\n",
    "Methods:\n",
    "- Phase synchronization index\n",
    "- Coherence\n",
    "- Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_synchronization_index(phi1, phi2):\n",
    "    \"\"\"\n",
    "    Compute phase synchronization index between two signals.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    phi1, phi2 : array_like\n",
    "        Instantaneous phases of two signals\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    psi : float\n",
    "        Phase synchronization index (0 to 1)\n",
    "    \"\"\"\n",
    "    # Phase difference\n",
    "    phase_diff = phi1 - phi2\n",
    "    \n",
    "    # Circular mean (order parameter)\n",
    "    psi = np.abs(np.mean(np.exp(1j * phase_diff)))\n",
    "    \n",
    "    return psi\n",
    "\n",
    "\n",
    "def compute_coherence(signal1, signal2, fs, nperseg=256):\n",
    "    \"\"\"\n",
    "    Compute magnitude-squared coherence between two signals.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    signal1, signal2 : array_like\n",
    "        Input time series\n",
    "    fs : float\n",
    "        Sampling frequency\n",
    "    nperseg : int\n",
    "        Segment length\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mean_coherence : float\n",
    "        Mean coherence across frequencies\n",
    "    \"\"\"\n",
    "    freqs, Cxy = signal.coherence(signal1, signal2, fs=fs, nperseg=nperseg)\n",
    "    \n",
    "    # Mean coherence\n",
    "    mean_coherence = np.mean(Cxy)\n",
    "    \n",
    "    return mean_coherence\n",
    "\n",
    "\n",
    "def compute_coupling_features(eeg_signal, ecg_signal, eeg_phase, ecg_phase, fs):\n",
    "    \"\"\"\n",
    "    Compute cross-modal coupling features.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    eeg_signal, ecg_signal : array_like\n",
    "        Raw signals\n",
    "    eeg_phase, ecg_phase : array_like\n",
    "        Instantaneous phases\n",
    "    fs : float\n",
    "        Sampling frequency\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    features : dict\n",
    "        Coupling features\n",
    "    \"\"\"\n",
    "    features = {\n",
    "        'phase_sync': phase_synchronization_index(eeg_phase, ecg_phase),\n",
    "        'coherence': compute_coherence(eeg_signal, ecg_signal, fs)\n",
    "    }\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def compute_delta_C(current_features, baseline_features):\n",
    "    \"\"\"\n",
    "    Compute coupling deviation from baseline.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    current_features : dict\n",
    "        Coupling features for current window\n",
    "    baseline_features : dict\n",
    "        Coupling features for baseline window\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    delta_c : float\n",
    "        Normalized coupling deviation\n",
    "    \"\"\"\n",
    "    # Phase synchronization deviation\n",
    "    ps_dev = abs(\n",
    "        current_features['phase_sync'] - baseline_features['phase_sync']\n",
    "    )\n",
    "    \n",
    "    # Coherence deviation\n",
    "    coh_dev = abs(\n",
    "        current_features['coherence'] - baseline_features['coherence']\n",
    "    )\n",
    "    \n",
    "    # Combined coupling deviation\n",
    "    delta_c = 0.5 * ps_dev + 0.5 * coh_dev\n",
    "    \n",
    "    return delta_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Demonstration with Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic EEG and HRV signals with regime change\n",
    "np.random.seed(42)\n",
    "fs = 250  # Hz\n",
    "duration = 30  # seconds\n",
    "t = np.linspace(0, duration, fs * duration)\n",
    "transition_time = 15\n",
    "\n",
    "# EEG: alpha to beta transition\n",
    "alpha_amp = np.where(t < transition_time, 1.0, 0.3)\n",
    "beta_amp = np.where(t < transition_time, 0.3, 1.0)\n",
    "eeg = alpha_amp * np.sin(2 * np.pi * 10 * t) + \\\n",
    "      beta_amp * np.sin(2 * np.pi * 20 * t) + \\\n",
    "      0.2 * np.random.randn(len(t))\n",
    "\n",
    "# HRV: LF/HF balance shift\n",
    "lf_amp = np.where(t < transition_time, 5, 10)\n",
    "hf_amp = np.where(t < transition_time, 10, 5)\n",
    "hrv = 70 + lf_amp * np.sin(2 * np.pi * 0.1 * t) + \\\n",
    "      hf_amp * np.sin(2 * np.pi * 0.25 * t) + \\\n",
    "      2 * np.random.randn(len(t))\n",
    "\n",
    "# Extract phases\n",
    "eeg_phase = np.unwrap(np.angle(hilbert(eeg)))\n",
    "hrv_phase = np.unwrap(np.angle(hilbert(hrv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define baseline and evaluation windows\n",
    "baseline_mask = t < 10\n",
    "eval_mask = (t >= 15) & (t < 20)\n",
    "\n",
    "# Compute features for baseline\n",
    "baseline_spectral_eeg = compute_spectral_features(eeg[baseline_mask], fs)\n",
    "baseline_spectral_hrv = compute_spectral_features(hrv[baseline_mask], fs)\n",
    "baseline_info_eeg = compute_information_features(eeg[baseline_mask])\n",
    "baseline_coupling = compute_coupling_features(\n",
    "    eeg[baseline_mask], hrv[baseline_mask],\n",
    "    eeg_phase[baseline_mask], hrv_phase[baseline_mask], fs\n",
    ")\n",
    "\n",
    "# Compute features for evaluation window\n",
    "eval_spectral_eeg = compute_spectral_features(eeg[eval_mask], fs)\n",
    "eval_spectral_hrv = compute_spectral_features(hrv[eval_mask], fs)\n",
    "eval_info_eeg = compute_information_features(eeg[eval_mask])\n",
    "eval_coupling = compute_coupling_features(\n",
    "    eeg[eval_mask], hrv[eval_mask],\n",
    "    eeg_phase[eval_mask], hrv_phase[eval_mask], fs\n",
    ")\n",
    "\n",
    "# Compute deviations\n",
    "delta_s = compute_delta_S(eval_spectral_hrv, baseline_spectral_hrv)\n",
    "delta_i = compute_delta_I(eval_info_eeg, baseline_info_eeg)\n",
    "delta_c = compute_delta_C(eval_coupling, baseline_coupling)\n",
    "\n",
    "print(\"=== Deviation Metrics ===\")\n",
    "print(f\"ΔS (Spectral deviation): {delta_s:.4f}\")\n",
    "print(f\"ΔI (Information deviation): {delta_i:.4f}\")\n",
    "print(f\"ΔC (Coupling deviation): {delta_c:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Unified Instability Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_instability_functional(delta_s, delta_i, delta_c, \n",
    "                                   alpha=0.4, beta=0.3, gamma=0.3):\n",
    "    \"\"\"\n",
    "    Compute unified instability functional ΔΦ(t).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    delta_s, delta_i, delta_c : float\n",
    "        Individual deviation terms\n",
    "    alpha, beta, gamma : float\n",
    "        Weights (must sum to 1)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    delta_phi : float\n",
    "        Unified instability measure\n",
    "    \"\"\"\n",
    "    assert abs(alpha + beta + gamma - 1.0) < 1e-6, \"Weights must sum to 1\"\n",
    "    \n",
    "    delta_phi = alpha * abs(delta_s) + beta * abs(delta_i) + gamma * abs(delta_c)\n",
    "    \n",
    "    return delta_phi\n",
    "\n",
    "\n",
    "# Compute unified functional\n",
    "delta_phi = compute_instability_functional(delta_s, delta_i, delta_c)\n",
    "\n",
    "print(f\"\\nΔΦ(t) = {delta_phi:.4f}\")\n",
    "print(f\"  = {0.4:.1f}×{delta_s:.4f} + {0.3:.1f}×{delta_i:.4f} + {0.3:.1f}×{delta_c:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization of Feature Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICE triangle visualization\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Triangle vertices (equilateral)\n",
    "vertices = np.array([\n",
    "    [0, 0],           # Information\n",
    "    [1, 0],           # Energy\n",
    "    [0.5, np.sqrt(3)/2]  # Coherence\n",
    "])\n",
    "\n",
    "triangle = plt.Polygon(vertices, fill=False, edgecolor='black', linewidth=2)\n",
    "ax.add_patch(triangle)\n",
    "\n",
    "# Convert (I, C, E) to barycentric coordinates\n",
    "# Normalize deviations\n",
    "total = delta_i + delta_c + delta_s\n",
    "if total > 0:\n",
    "    i_norm = delta_i / total\n",
    "    c_norm = delta_c / total\n",
    "    e_norm = delta_s / total\n",
    "else:\n",
    "    i_norm = c_norm = e_norm = 1/3\n",
    "\n",
    "# Barycentric to Cartesian\n",
    "point = i_norm * vertices[0] + e_norm * vertices[1] + c_norm * vertices[2]\n",
    "\n",
    "# Plot baseline (center)\n",
    "baseline_point = np.mean(vertices, axis=0)\n",
    "ax.plot(*baseline_point, 'go', markersize=12, label='Baseline')\n",
    "\n",
    "# Plot evaluation point\n",
    "ax.plot(*point, 'ro', markersize=12, label='Evaluation')\n",
    "\n",
    "# Arrow from baseline to evaluation\n",
    "ax.arrow(baseline_point[0], baseline_point[1],\n",
    "         point[0] - baseline_point[0], point[1] - baseline_point[1],\n",
    "         head_width=0.03, head_length=0.03, fc='red', ec='red', alpha=0.6)\n",
    "\n",
    "# Labels\n",
    "ax.text(vertices[0][0]-0.1, vertices[0][1]-0.1, 'Information (I)',\n",
    "        fontsize=12, ha='right')\n",
    "ax.text(vertices[1][0]+0.1, vertices[1][1]-0.1, 'Energy (E)',\n",
    "        fontsize=12, ha='left')\n",
    "ax.text(vertices[2][0], vertices[2][1]+0.1, 'Coherence (C)',\n",
    "        fontsize=12, ha='center')\n",
    "\n",
    "ax.set_xlim(-0.2, 1.2)\n",
    "ax.set_ylim(-0.2, 1.0)\n",
    "ax.set_aspect('equal')\n",
    "ax.axis('off')\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title('ICE Stability Triangle', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nICE coordinates (normalized):\")\n",
    "print(f\"  Information: {i_norm:.3f}\")\n",
    "print(f\"  Coherence:   {c_norm:.3f}\")\n",
    "print(f\"  Energy:      {e_norm:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **ΔS computation**: Spectral/morphological deviation (LF/HF ratio, band powers)\n",
    "2. **ΔI computation**: Information-theoretic deviation (entropy measures)\n",
    "3. **ΔC computation**: Cross-modal coupling deviation (phase sync, coherence)\n",
    "4. **ΔΦ functional**: Weighted combination with transparent parameters\n",
    "5. **ICE visualization**: Interpretive mapping in information-coherence-energy space\n",
    "\n",
    "All features are deterministic, traceable, and admit direct ablation testing.\n",
    "\n",
    "**Next steps**: See `03_eeg_validation.ipynb` for real EEG dataset validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
